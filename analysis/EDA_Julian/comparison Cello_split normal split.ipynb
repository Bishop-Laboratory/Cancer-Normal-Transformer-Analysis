{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: cello-multiplier 0.0.1\n",
      "Uninstalling cello-multiplier-0.0.1:\n",
      "  Successfully uninstalled cello-multiplier-0.0.1\n",
      "Collecting git+https://github.com/Bishop-Laboratory/CellO-MultiPLIER.git\n",
      "  Cloning https://github.com/Bishop-Laboratory/CellO-MultiPLIER.git to c:\\users\\julia\\appdata\\local\\temp\\pip-req-build-x6xfoi70\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\julia\\anaconda3\\lib\\site-packages (from cello-multiplier==0.0.1) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: sklearn in c:\\users\\julia\\anaconda3\\lib\\site-packages (from cello-multiplier==0.0.1) (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\users\\julia\\anaconda3\\lib\\site-packages (from cello-multiplier==0.0.1) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas in c:\\users\\julia\\anaconda3\\lib\\site-packages (from cello-multiplier==0.0.1) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\julia\\anaconda3\\lib\\site-packages (from sklearn->cello-multiplier==0.0.1) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas->cello-multiplier==0.0.1) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas->cello-multiplier==0.0.1) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->cello-multiplier==0.0.1) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->cello-multiplier==0.0.1) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->cello-multiplier==0.0.1) (1.15.0)\n",
      "Building wheels for collected packages: cello-multiplier\n",
      "  Building wheel for cello-multiplier (PEP 517): started\n",
      "  Building wheel for cello-multiplier (PEP 517): finished with status 'done'\n",
      "  Created wheel for cello-multiplier: filename=cello_multiplier-0.0.1-py3-none-any.whl size=26280814 sha256=32f3751244f23595dbd58ba745526640e57768d868b37cde389d9b123ce5f03e\n",
      "  Stored in directory: C:\\Users\\julia\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-_ws2_8uy\\wheels\\4e\\a2\\13\\7caa6e484f87d31e5fbaef2a13beef986a14a300708738afa0\n",
      "Successfully built cello-multiplier\n",
      "Installing collected packages: cello-multiplier\n",
      "Successfully installed cello-multiplier-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall cello_multiplier --yes\n",
    "!pip install -U git+https://github.com/Bishop-Laboratory/CellO-MultiPLIER.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cello_multiplier as cm\n",
    "from onto_lib import general_ontology_tools as got\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "B_df, Z_df, labels, per_gene_mean, per_gene_std, train_dummies_specific, train_dummies_full, classifiers = cm.get_default_mats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CellO split \n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "split_dir = Path('data/CellO_data/bulk_RNA_seq_training_set/pretraining_validation_split/')\n",
    "\n",
    "\n",
    "\n",
    "with open(split_dir / 'validation_bulk_experiments.json', 'r') as f:\n",
    "    validation_egs = json.load(f)\n",
    "\n",
    "with open(split_dir / 'pre_training_bulk_experiments.json', 'r') as f:\n",
    "    train_egs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full CellO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               TSPAN6      TNMD      DPM1     SCYL3  C1orf112       FGR  \\\n",
       "SRX890545   0.071963  0.068414  3.718085  2.184815  1.490935  6.995514   \n",
       "SRX1067711  0.033104  0.000000  3.743323  1.990195  1.780348  6.565519   \n",
       "SRX1067710  0.233484  0.000000  3.376271  1.523096  0.611052  5.667817   \n",
       "SRX762971   0.000000  0.000000  0.270898  0.272666  0.046180  4.310495   \n",
       "SRX762970   0.000000  0.000000  0.000000  0.153331  0.029985  3.570165   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "SRX3399308  0.900313  0.000000  4.034299  2.548069  1.914284  6.135145   \n",
       "SRX3399309  0.317015  0.000000  3.972622  2.634532  2.009371  6.394950   \n",
       "SRX3399310  0.799190  0.000000  4.109202  2.661645  2.445280  6.295505   \n",
       "SRX3399311  0.044163  0.000000  4.007751  2.015217  1.989733  6.363111   \n",
       "SRX3399312  1.064050  0.000000  3.668019  2.255745  2.194389  5.908714   \n",
       "\n",
       "                 CFH     FUCA2      GCLC      NFYA  ...  MIR6715B  \\\n",
       "SRX890545   0.629519  3.892468  3.241940  2.960884  ...       0.0   \n",
       "SRX1067711  0.045174  3.519702  3.266680  2.425106  ...       0.0   \n",
       "SRX1067710  0.013306  3.271395  3.490619  2.419673  ...       0.0   \n",
       "SRX762971   0.048563  0.505901  1.021726  0.468655  ...       0.0   \n",
       "SRX762970   0.012488  0.376561  0.298916  0.148210  ...       0.0   \n",
       "...              ...       ...       ...       ...  ...       ...   \n",
       "SRX3399308  1.561809  3.504841  2.099581  2.509156  ...       0.0   \n",
       "SRX3399309  1.277340  3.693114  2.188385  2.900505  ...       0.0   \n",
       "SRX3399310  1.314905  3.792382  1.471354  3.156924  ...       0.0   \n",
       "SRX3399311  0.788769  3.855940  2.337722  3.061316  ...       0.0   \n",
       "SRX3399312  1.361077  3.788669  2.589609  2.899395  ...       0.0   \n",
       "\n",
       "            RP11-434E6.5  MIR3116-2  RP11-158M9.1  MIR3202-2  CTD-2331H12.9  \\\n",
       "SRX890545            0.0        0.0      0.000000        0.0            0.0   \n",
       "SRX1067711           0.0        0.0      0.084583        0.0            0.0   \n",
       "SRX1067710           0.0        0.0      0.073274        0.0            0.0   \n",
       "SRX762971            0.0        0.0      0.061147        0.0            0.0   \n",
       "SRX762970            0.0        0.0      0.000000        0.0            0.0   \n",
       "...                  ...        ...           ...        ...            ...   \n",
       "SRX3399308           0.0        0.0      0.197238        0.0            0.0   \n",
       "SRX3399309           0.0        0.0      0.198363        0.0            0.0   \n",
       "SRX3399310           0.0        0.0      0.000000        0.0            0.0   \n",
       "SRX3399311           0.0        0.0      0.071303        0.0            0.0   \n",
       "SRX3399312           0.0        0.0      0.000000        0.0            0.0   \n",
       "\n",
       "            RP11-122G18.12  RP5-937E21.8  RP11-606M12.1   MIR4481  \n",
       "SRX890545         1.208610      0.086928       0.149827  0.997044  \n",
       "SRX1067711        0.647963      0.000000       0.000000  0.000000  \n",
       "SRX1067710        0.697612      0.000000       0.306894  0.000000  \n",
       "SRX762971         0.751671      0.000000       0.000000  0.000000  \n",
       "SRX762970         0.520262      0.000000       0.000000  0.000000  \n",
       "...                    ...           ...            ...       ...  \n",
       "SRX3399308        0.976151      0.000000       0.455072  0.000000  \n",
       "SRX3399309        1.115170      0.000000       0.386765  0.000000  \n",
       "SRX3399310        0.698829      0.000000       0.148570  0.000000  \n",
       "SRX3399311        1.192115      0.715472       0.605566  3.314630  \n",
       "SRX3399312        0.810953      0.482831       0.157699  0.000000  \n",
       "\n",
       "[4293 rows x 55904 columns]>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cello_data = pd.read_csv(\"plierInput.mat.csv\").T\n",
    "cello_data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of LR using CellO split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3609, 55904)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_df = cello_data[cello_data.index.isin(train_egs)]\n",
    "train_Y_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 55904)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y_df = cello_data[cello_data.index.isin(validation_egs)]\n",
    "test_Y_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of samples by celltypes\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "sample2types = {\n",
    "            sample: list(map(got.get_term_name, types_ids))\n",
    "            for sample, types_ids in labels.items()\n",
    "        }\n",
    "\n",
    "types_per_b_samples = B_df.index.map(sample2types).values\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "types_per_b_samples = B_df.index.map(sample2types).values\n",
    "\n",
    "samples_dummies = pd.DataFrame(mlb.fit_transform(types_per_b_samples), columns=mlb.classes_, index=B_df.index)\n",
    "\n",
    "celltypes = samples_dummies.columns.tolist()\n",
    "\n",
    "type2samples = {\n",
    "    type_: samples_dummies.index[samples_dummies[type_] == 1].tolist()\n",
    "    for type_ in celltypes\n",
    "}\n",
    "types_sizes = samples_dummies.sum() # no of times a celltype occours in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target list for given cell type with 1 being that cell type and 0 being any other cell type\n",
    "def set_target(celltype, type2samples, train_Y_df, test_Y_df,):\n",
    "    samplelist = type2samples[celltype]\n",
    "    samplelist_train = [x for x in samplelist if x in train_Y_df.index.values]\n",
    "    samplelist_test = [x for x in samplelist if x in test_Y_df.index.values]\n",
    "    \n",
    "    target_train = pd.Series(0,index = train_Y_df.index)\n",
    "    target_train.loc[samplelist_train] = 1\n",
    "    \n",
    "    target_test = pd.Series(0,index = test_Y_df.index)\n",
    "    target_test.loc[samplelist_test] = 1\n",
    "    \n",
    "    train_Y_transformed = train_Y_df #used to contain standard scaling, removed\n",
    "    test_Y_transformed = test_Y_df\n",
    "    \n",
    "    return(target_train.values, target_test.values, train_Y_transformed, test_Y_transformed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscore(p, r):\n",
    "    denom = p + r or 1\n",
    "\n",
    "    return 2*(p * r) / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_with_data = types_sizes.index.values # all celltypes that occour in the data\n",
    "all_types = samples_dummies.columns # get list of celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_classify(solver,penalty):\n",
    "\n",
    "    warnings.filterwarnings('ignore') #gets rid of sklearn convergence warning\n",
    "\n",
    "    successful_celltypes = []\n",
    "    unsuccessful_celltypes = []\n",
    "    test_prs = []\n",
    "    test_precision = []\n",
    "    test_recall = []\n",
    "    fscores = []\n",
    "    aps = []\n",
    "    for cell_type in tqdm(all_types):\n",
    "        train_target, train_test, train_data, test_data = set_target(\n",
    "            cell_type, type2samples, train_Y_df, test_Y_df\n",
    "        )\n",
    "\n",
    "        if(1 in train_target and 1 in train_test and 0 in train_target and 0 in train_test):\n",
    "            # lasso penalty\n",
    "            clf = LogisticRegression(solver = solver,penalty = penalty,random_state=111 )\n",
    "\n",
    "            clf.fit(train_data, train_target)\n",
    "            target_pred = clf.predict(test_data)\n",
    "            test_pr = metrics.average_precision_score(train_test, target_pred)\n",
    "            test_precision += [precision_score(train_test, target_pred)]\n",
    "            test_recall += [recall_score(train_test, target_pred)]\n",
    "            aps += [average_precision_score(train_test, target_pred)]\n",
    "            fscores += [fscore(test_precision[-1], test_recall[-1])]\n",
    "            successful_celltypes += [cell_type]\n",
    "           \n",
    "            \n",
    "        else:\n",
    "            unsuccessful_celltypes += [cell_type]\n",
    "\n",
    "    p = np.mean(test_precision)\n",
    "    r = np.mean(test_recall)\n",
    "    f = np.mean(fscores)\n",
    "    f_micro = fscore(p, r) \n",
    "    ap = np.mean(aps)\n",
    "\n",
    "    \n",
    "    print(f'precision: {p:.4f}, recall: {r:.4f}, f1: {f:.4f}, f1 micro avg: {f_micro:.4f}, average precision avg: {ap:.4f}')#\n",
    "    \n",
    "    return aps # returns the average precision of every successfully trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3d476646994148afc7e5e5dcf2643c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=317.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision: 0.6261, recall: 0.5168, f1: 0.5402, f1 micro avg: 0.5662, average precision avg: 0.4914\n"
     ]
    }
   ],
   "source": [
    "report = LR_classify(\"liblinear\",\"l1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of LR using split of 30 % test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = cello_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target list for given cell type with 1 being that cell type and 0 being any other cell type\n",
    "def set_target_full(celltype, type2samples, data):\n",
    "    samplelist = type2samples[celltype]\n",
    "    samplelist = [x for x in samplelist if x in data.index.values]\n",
    "    \n",
    "    target = pd.Series(0,index = data.index)\n",
    "    target.loc[samplelist] = 1\n",
    "    \n",
    "    train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.30, random_state=111)\n",
    "    return(train_data, test_data, train_target.values, test_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_classify_sklearn_split(solver,penalty):\n",
    "\n",
    "    warnings.filterwarnings('ignore') #gets rid of sklearn convergence warning\n",
    "\n",
    "    successful_celltypes = []\n",
    "    unsuccessful_celltypes = []\n",
    "    test_prs = []\n",
    "    test_precision = []\n",
    "    test_recall = []\n",
    "    fscores = []\n",
    "    aps = []\n",
    "    for cell_type in tqdm(all_types):\n",
    "        train_data, test_data, train_target, test_target = set_target_full(\n",
    "            cell_type, type2samples, data\n",
    "        )\n",
    "\n",
    "        if(1 in train_target and 1 in test_target and 0 in train_target and 0 in test_target):\n",
    "            # lasso penalty\n",
    "            clf = LogisticRegression(solver = solver,penalty = penalty,random_state=111 )\n",
    "\n",
    "            clf.fit(train_data, train_target)\n",
    "            target_pred = clf.predict(test_data)\n",
    "            test_pr = metrics.average_precision_score(test_target, target_pred)\n",
    "            test_precision += [precision_score(test_target, target_pred)]\n",
    "            test_recall += [recall_score(test_target, target_pred)]\n",
    "            aps += [average_precision_score(test_target, target_pred)]\n",
    "            fscores += [fscore(test_precision[-1], test_recall[-1])]\n",
    "            successful_celltypes += [cell_type]\n",
    "           \n",
    "            \n",
    "        else:\n",
    "            unsuccessful_celltypes += [cell_type]\n",
    "\n",
    "    p = np.mean(test_precision)\n",
    "    r = np.mean(test_recall)\n",
    "    f = np.mean(fscores)\n",
    "    f_micro = fscore(p, r) \n",
    "    ap = np.mean(aps)\n",
    "\n",
    "    \n",
    "    print(f'precision: {p:.4f}, recall: {r:.4f}, f1: {f:.4f}, f1 micro avg: {f_micro:.4f}, average precision avg: {ap:.4f}')#\n",
    "    \n",
    "    return aps # returns the average precision of every successfully trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee1299461c3482c8af0b4d01f16a865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=317.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision: 0.8804, recall: 0.8468, f1: 0.8512, f1 micro avg: 0.8633, average precision avg: 0.8136\n"
     ]
    }
   ],
   "source": [
    "report1 = LR_classify_sklearn_split(\"liblinear\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reportdf = pd.DataFrame(list(zip(report,report1)), columns = [\"CellO split\",\"Sklearn split\"])\n",
    "reportdf.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
